{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow.keras as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\n#from keras.applications.inception_v3 import InceptionV3\n\nfrom keras.applications import MobileNetV2, VGG19, VGG16, Xception, InceptionV3, InceptionResNetV2, DenseNet201\nimport cv2\nimport os\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[{"output_type":"stream","text":"/kaggle/input/face-mask-detection-dataset/submission.csv\n/kaggle/input/face-mask-detection-dataset/train.csv\n/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/meta.json\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/face-mask-detection-dataset/train.csv')\ndeneme = [1 if ((element=='face_with_mask') or  (element=='mask_surgical') or (element=='mask_colorful')) else 0 for element in data.classname]\ndata['Classification'] = deneme\ndata.drop(['x1', 'x2', 'y1', 'y2', 'classname'], axis =1, inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagrouped = data.groupby(['name'], as_index=False).sum()\ndatagrouped.Classification[datagrouped['Classification']>=1]=1\ndatagrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\nrre = cv2.imread(path+'3216.png')\nplt.imshow(rre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\ntrainingdata = np.zeros((1,256,256,3))\nk = 0\nfor element in datagrouped['name']:\n    resim = cv2.imread(path+element)\n    resim = cv2.resize(resim,(256,256), interpolation = cv2.INTER_NEAREST)\n    resim = (resim-np.mean(resim))/np.std(resim)\n    trainingdata = np.append(trainingdata, resim[np.newaxis,...], axis=0) \n    if k==1000:\n        break\n    k+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ag = np.delete(trainingdata,0, axis=0)\nag.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(ag[25,...])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(ag[25,125:225,50:150,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(ag[25,...,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(ag[25,...]*(ag[25,...]>0.6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainingdata[1000:1500,...].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labeldata = np.zeros((1000,2))\n#for el, em in enumerate(labeldata):\n#    if em == 0:\n#        continue\n#    else:        \nlabeldata = datagrouped.Classification[:1001]\nlabeldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = tf.Input(shape=(256, 256, 3))\n#model = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n#for layer in model.layers[:-3]:\n#    layer.trainable = False\nx = tf.layers.Conv2D(128,(3, 3), strides=(1, 1), activation='relu')(input_layer)\nx = tf.layers.Conv2D(128,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(128,(3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.MaxPool2D((2, 2), strides=(2, 2))(x)\nx = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\nx = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\nx = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(256,(3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.MaxPool2D((2, 2), strides=(2, 2))(x)\nx = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\nx = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\nx = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(512,(3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.MaxPool2D((2, 2), strides=(2, 2))(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\nx = tf.layers.Dropout(0.5)(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(64,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(32,(3, 3), strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(256,(3, 3), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(256, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), strides=(2, 2))(x)\n#x = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Conv2D(16, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.Conv2D(16, (1, 1), strides=(2, 2), activation='relu')(x)\nx = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Conv2D(1, (3, 3), strides=(2, 2), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.GlobalMaxPooling2D()(x)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Lambda(lambda x: x**2)(x)\nx = tf.layers.Flatten()(x)\n#x = tf.layers.GlobalAveragePooling2D()(x)\n#x = tf.layers.Dense(1024, activation='relu')(x)\n#x = tf.layers.Dense(2048, activation='relu')(x)\n#x = tf.layers.Dense(1024, activation='relu')(x)\nx = tf.layers.Dense(128, activation='relu')(x)\nx = tf.layers.Dense(256, activation='relu')(x)\nx = tf.layers.Dense(128, activation='relu')(x)\nx = tf.layers.Dense(1, activation='sigmoid')(x)\ncmodel = tf.Model(input_layer, x)\ncmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nfor layer in model.layers[:-8]:\n    layer.trainable = False\nx = tf.layers.GlobalAveragePooling2D()(model.output)\n#x = tf.layers.Flatten()(model.output)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Dropout(0.5)(x)\n#x = tf.layers.Dense(2048, activation='relu')(x)\nx = tf.layers.Dense(8, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Dense(32, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Dense(64, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Dense(128, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.5)(x)\nx = tf.layers.Dense(256, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(512, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(1024, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(1024, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(1024, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(512, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(256, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.8)(x)\nx = tf.layers.Dense(128, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dense(64, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dense(32, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dense(16, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dense(8, activation=tf.layers.PReLU())(x)\nx = tf.layers.BatchNormalization()(x)\nx = tf.layers.Dropout(0.5)(x)\n#x = tf.layers.Dropout(0.8)(x)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Dropout(0.5)(x)\n#x = tf.layers.Dense(1024, activation='relu')(x)\n#x = tf.layers.BatchNormalization()(x)\n#x = tf.layers.Dropout(0.5)(x)\n#x = tf.layers.ActivityRegularization()(x)\nx = tf.layers.Dense(1, activation='sigmoid')(x)\nm = tf.Model(inputs=model.input, outputs=x)\n\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.compile(loss=tf.losses.BinaryCrossentropy(), optimizer='nadam', metrics=[\"accuracy\"])\nm.fit(ag[0:800,...], labeldata[0:800], validation_data = (ag[800:1000,...],labeldata[800:1000]), epochs=300, batch_size=100)","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/200\n8/8 [==============================] - 31s 4s/step - loss: 0.9617 - accuracy: 0.4700 - val_loss: 0.6920 - val_accuracy: 0.8050\nEpoch 2/200\n8/8 [==============================] - 30s 4s/step - loss: 0.8931 - accuracy: 0.4900 - val_loss: 0.6909 - val_accuracy: 0.8200\nEpoch 3/200\n8/8 [==============================] - 31s 4s/step - loss: 0.8981 - accuracy: 0.4900 - val_loss: 0.6788 - val_accuracy: 0.8200\nEpoch 4/200\n8/8 [==============================] - 35s 4s/step - loss: 0.8873 - accuracy: 0.4837 - val_loss: 0.6773 - val_accuracy: 0.8200\nEpoch 5/200\n8/8 [==============================] - 31s 4s/step - loss: 0.8567 - accuracy: 0.4850 - val_loss: 0.6685 - val_accuracy: 0.8200\nEpoch 6/200\n8/8 [==============================] - 30s 4s/step - loss: 0.8493 - accuracy: 0.4812 - val_loss: 0.6785 - val_accuracy: 0.8200\nEpoch 7/200\n8/8 [==============================] - 30s 4s/step - loss: 0.8249 - accuracy: 0.4988 - val_loss: 0.6640 - val_accuracy: 0.8200\nEpoch 8/200\n8/8 [==============================] - 32s 4s/step - loss: 0.8209 - accuracy: 0.5300 - val_loss: 0.6639 - val_accuracy: 0.8200\nEpoch 9/200\n8/8 [==============================] - 29s 4s/step - loss: 0.7953 - accuracy: 0.5125 - val_loss: 0.6691 - val_accuracy: 0.8200\nEpoch 10/200\n8/8 [==============================] - 29s 4s/step - loss: 0.8038 - accuracy: 0.5200 - val_loss: 0.6677 - val_accuracy: 0.8200\nEpoch 11/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7785 - accuracy: 0.5275 - val_loss: 0.6612 - val_accuracy: 0.8200\nEpoch 12/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7587 - accuracy: 0.5263 - val_loss: 0.6502 - val_accuracy: 0.8200\nEpoch 13/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7452 - accuracy: 0.5562 - val_loss: 0.6571 - val_accuracy: 0.8200\nEpoch 14/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7633 - accuracy: 0.5337 - val_loss: 0.6689 - val_accuracy: 0.8200\nEpoch 15/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7293 - accuracy: 0.5600 - val_loss: 0.6558 - val_accuracy: 0.8200\nEpoch 16/200\n8/8 [==============================] - 43s 5s/step - loss: 0.7072 - accuracy: 0.5650 - val_loss: 0.6325 - val_accuracy: 0.8200\nEpoch 17/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7386 - accuracy: 0.5550 - val_loss: 0.6330 - val_accuracy: 0.8200\nEpoch 18/200\n8/8 [==============================] - 29s 4s/step - loss: 0.7065 - accuracy: 0.5638 - val_loss: 0.6141 - val_accuracy: 0.8200\nEpoch 19/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7178 - accuracy: 0.5750 - val_loss: 0.5901 - val_accuracy: 0.8200\nEpoch 20/200\n8/8 [==============================] - 29s 4s/step - loss: 0.7259 - accuracy: 0.5813 - val_loss: 0.5566 - val_accuracy: 0.8200\nEpoch 21/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7099 - accuracy: 0.5950 - val_loss: 0.5460 - val_accuracy: 0.8200\nEpoch 22/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6689 - accuracy: 0.6150 - val_loss: 0.5602 - val_accuracy: 0.8200\nEpoch 23/200\n8/8 [==============================] - 31s 4s/step - loss: 0.7189 - accuracy: 0.5800 - val_loss: 0.5672 - val_accuracy: 0.8200\nEpoch 24/200\n8/8 [==============================] - 30s 4s/step - loss: 0.7206 - accuracy: 0.5850 - val_loss: 0.5817 - val_accuracy: 0.8200\nEpoch 25/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6851 - accuracy: 0.6175 - val_loss: 0.5753 - val_accuracy: 0.8200\nEpoch 26/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6860 - accuracy: 0.6037 - val_loss: 0.5680 - val_accuracy: 0.8200\nEpoch 27/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6572 - accuracy: 0.6538 - val_loss: 0.5598 - val_accuracy: 0.8200\nEpoch 28/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6921 - accuracy: 0.5975 - val_loss: 0.5567 - val_accuracy: 0.8200\nEpoch 29/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6729 - accuracy: 0.6450 - val_loss: 0.5390 - val_accuracy: 0.8200\nEpoch 30/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6505 - accuracy: 0.6350 - val_loss: 0.5297 - val_accuracy: 0.8200\nEpoch 31/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6596 - accuracy: 0.6463 - val_loss: 0.5221 - val_accuracy: 0.8200\nEpoch 32/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6501 - accuracy: 0.6587 - val_loss: 0.5236 - val_accuracy: 0.8200\nEpoch 33/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6275 - accuracy: 0.6500 - val_loss: 0.5181 - val_accuracy: 0.8200\nEpoch 34/200\n8/8 [==============================] - 41s 5s/step - loss: 0.6588 - accuracy: 0.6400 - val_loss: 0.5200 - val_accuracy: 0.8200\nEpoch 35/200\n8/8 [==============================] - 33s 4s/step - loss: 0.6811 - accuracy: 0.6488 - val_loss: 0.5157 - val_accuracy: 0.8200\nEpoch 36/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6569 - accuracy: 0.6587 - val_loss: 0.5201 - val_accuracy: 0.8200\nEpoch 37/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6526 - accuracy: 0.6425 - val_loss: 0.5159 - val_accuracy: 0.8200\nEpoch 38/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6619 - accuracy: 0.6662 - val_loss: 0.5185 - val_accuracy: 0.8200\nEpoch 39/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6592 - accuracy: 0.6825 - val_loss: 0.5188 - val_accuracy: 0.8200\nEpoch 40/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6409 - accuracy: 0.6775 - val_loss: 0.5135 - val_accuracy: 0.8200\nEpoch 41/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6524 - accuracy: 0.6712 - val_loss: 0.5138 - val_accuracy: 0.8200\nEpoch 42/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6724 - accuracy: 0.6612 - val_loss: 0.5131 - val_accuracy: 0.8200\nEpoch 43/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6435 - accuracy: 0.7038 - val_loss: 0.5173 - val_accuracy: 0.8200\nEpoch 44/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6400 - accuracy: 0.6775 - val_loss: 0.5243 - val_accuracy: 0.8200\nEpoch 45/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6451 - accuracy: 0.6862 - val_loss: 0.5271 - val_accuracy: 0.8200\nEpoch 46/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6426 - accuracy: 0.6875 - val_loss: 0.5221 - val_accuracy: 0.8200\nEpoch 47/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6352 - accuracy: 0.6750 - val_loss: 0.5205 - val_accuracy: 0.8200\nEpoch 48/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6271 - accuracy: 0.6963 - val_loss: 0.5293 - val_accuracy: 0.8200\nEpoch 49/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6204 - accuracy: 0.7025 - val_loss: 0.5325 - val_accuracy: 0.8200\nEpoch 50/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6158 - accuracy: 0.7163 - val_loss: 0.5321 - val_accuracy: 0.8200\nEpoch 51/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6097 - accuracy: 0.7225 - val_loss: 0.5266 - val_accuracy: 0.8200\nEpoch 52/200\n8/8 [==============================] - 42s 5s/step - loss: 0.6271 - accuracy: 0.7212 - val_loss: 0.5226 - val_accuracy: 0.8200\nEpoch 53/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6197 - accuracy: 0.7113 - val_loss: 0.5236 - val_accuracy: 0.8200\nEpoch 54/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6120 - accuracy: 0.7050 - val_loss: 0.5231 - val_accuracy: 0.8200\nEpoch 55/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6263 - accuracy: 0.7050 - val_loss: 0.5254 - val_accuracy: 0.8200\nEpoch 56/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6078 - accuracy: 0.7225 - val_loss: 0.5279 - val_accuracy: 0.8200\nEpoch 57/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6098 - accuracy: 0.7150 - val_loss: 0.5252 - val_accuracy: 0.8200\nEpoch 58/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6165 - accuracy: 0.7100 - val_loss: 0.5265 - val_accuracy: 0.8200\nEpoch 59/200\n","name":"stdout"},{"output_type":"stream","text":"8/8 [==============================] - 30s 4s/step - loss: 0.6159 - accuracy: 0.7150 - val_loss: 0.5206 - val_accuracy: 0.8200\nEpoch 60/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6146 - accuracy: 0.7150 - val_loss: 0.5186 - val_accuracy: 0.8200\nEpoch 61/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6356 - accuracy: 0.7100 - val_loss: 0.5241 - val_accuracy: 0.8200\nEpoch 62/200\n8/8 [==============================] - 32s 4s/step - loss: 0.6124 - accuracy: 0.7150 - val_loss: 0.5199 - val_accuracy: 0.8200\nEpoch 63/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6096 - accuracy: 0.7237 - val_loss: 0.5201 - val_accuracy: 0.8200\nEpoch 64/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6145 - accuracy: 0.7237 - val_loss: 0.5193 - val_accuracy: 0.8200\nEpoch 65/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6240 - accuracy: 0.7088 - val_loss: 0.5184 - val_accuracy: 0.8200\nEpoch 66/200\n8/8 [==============================] - 29s 4s/step - loss: 0.6108 - accuracy: 0.7300 - val_loss: 0.5169 - val_accuracy: 0.8200\nEpoch 67/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6042 - accuracy: 0.7150 - val_loss: 0.5160 - val_accuracy: 0.8200\nEpoch 68/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6077 - accuracy: 0.7225 - val_loss: 0.5193 - val_accuracy: 0.8200\nEpoch 69/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6128 - accuracy: 0.7188 - val_loss: 0.5184 - val_accuracy: 0.8200\nEpoch 70/200\n8/8 [==============================] - 42s 5s/step - loss: 0.6197 - accuracy: 0.7125 - val_loss: 0.5138 - val_accuracy: 0.8200\nEpoch 71/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6089 - accuracy: 0.7312 - val_loss: 0.5122 - val_accuracy: 0.8200\nEpoch 72/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5977 - accuracy: 0.7325 - val_loss: 0.5103 - val_accuracy: 0.8200\nEpoch 73/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6157 - accuracy: 0.7237 - val_loss: 0.5102 - val_accuracy: 0.8200\nEpoch 74/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6175 - accuracy: 0.7237 - val_loss: 0.5115 - val_accuracy: 0.8200\nEpoch 75/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5963 - accuracy: 0.7287 - val_loss: 0.5079 - val_accuracy: 0.8200\nEpoch 76/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6138 - accuracy: 0.7237 - val_loss: 0.5058 - val_accuracy: 0.8200\nEpoch 77/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6152 - accuracy: 0.7250 - val_loss: 0.5049 - val_accuracy: 0.8200\nEpoch 78/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5969 - accuracy: 0.7337 - val_loss: 0.5057 - val_accuracy: 0.8200\nEpoch 79/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6177 - accuracy: 0.7262 - val_loss: 0.5085 - val_accuracy: 0.8200\nEpoch 80/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6076 - accuracy: 0.7237 - val_loss: 0.5110 - val_accuracy: 0.8200\nEpoch 81/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5966 - accuracy: 0.7300 - val_loss: 0.5109 - val_accuracy: 0.8200\nEpoch 82/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6114 - accuracy: 0.7250 - val_loss: 0.5114 - val_accuracy: 0.8200\nEpoch 83/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6059 - accuracy: 0.7325 - val_loss: 0.5108 - val_accuracy: 0.8200\nEpoch 84/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5965 - accuracy: 0.7262 - val_loss: 0.5088 - val_accuracy: 0.8200\nEpoch 85/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5935 - accuracy: 0.7237 - val_loss: 0.5092 - val_accuracy: 0.8200\nEpoch 86/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5947 - accuracy: 0.7212 - val_loss: 0.5089 - val_accuracy: 0.8200\nEpoch 87/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6031 - accuracy: 0.7237 - val_loss: 0.5088 - val_accuracy: 0.8200\nEpoch 88/200\n8/8 [==============================] - 42s 5s/step - loss: 0.6000 - accuracy: 0.7262 - val_loss: 0.5091 - val_accuracy: 0.8200\nEpoch 89/200\n8/8 [==============================] - 32s 4s/step - loss: 0.5961 - accuracy: 0.7300 - val_loss: 0.5088 - val_accuracy: 0.8200\nEpoch 90/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5969 - accuracy: 0.7250 - val_loss: 0.5077 - val_accuracy: 0.8200\nEpoch 91/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6065 - accuracy: 0.7262 - val_loss: 0.5094 - val_accuracy: 0.8200\nEpoch 92/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6072 - accuracy: 0.7250 - val_loss: 0.5097 - val_accuracy: 0.8200\nEpoch 93/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5792 - accuracy: 0.7312 - val_loss: 0.5087 - val_accuracy: 0.8200\nEpoch 94/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5986 - accuracy: 0.7225 - val_loss: 0.5096 - val_accuracy: 0.8200\nEpoch 95/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5983 - accuracy: 0.7225 - val_loss: 0.5106 - val_accuracy: 0.8200\nEpoch 96/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5997 - accuracy: 0.7262 - val_loss: 0.5099 - val_accuracy: 0.8200\nEpoch 97/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5989 - accuracy: 0.7350 - val_loss: 0.5080 - val_accuracy: 0.8200\nEpoch 98/200\n8/8 [==============================] - 31s 4s/step - loss: 0.6012 - accuracy: 0.7225 - val_loss: 0.5085 - val_accuracy: 0.8200\nEpoch 99/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5976 - accuracy: 0.7237 - val_loss: 0.5094 - val_accuracy: 0.8200\nEpoch 100/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5897 - accuracy: 0.7312 - val_loss: 0.5081 - val_accuracy: 0.8200\nEpoch 101/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5984 - accuracy: 0.7262 - val_loss: 0.5093 - val_accuracy: 0.8200\nEpoch 102/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6091 - accuracy: 0.7275 - val_loss: 0.5079 - val_accuracy: 0.8200\nEpoch 103/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5901 - accuracy: 0.7262 - val_loss: 0.5086 - val_accuracy: 0.8200\nEpoch 104/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6003 - accuracy: 0.7262 - val_loss: 0.5098 - val_accuracy: 0.8200\nEpoch 105/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6040 - accuracy: 0.7200 - val_loss: 0.5093 - val_accuracy: 0.8200\nEpoch 106/200\n8/8 [==============================] - 39s 5s/step - loss: 0.5939 - accuracy: 0.7300 - val_loss: 0.5090 - val_accuracy: 0.8200\nEpoch 107/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5978 - accuracy: 0.7312 - val_loss: 0.5084 - val_accuracy: 0.8200\nEpoch 108/200\n8/8 [==============================] - 30s 4s/step - loss: 0.6014 - accuracy: 0.7300 - val_loss: 0.5085 - val_accuracy: 0.8200\nEpoch 109/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5964 - accuracy: 0.7287 - val_loss: 0.5091 - val_accuracy: 0.8200\nEpoch 110/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5903 - accuracy: 0.7262 - val_loss: 0.5085 - val_accuracy: 0.8200\nEpoch 111/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5957 - accuracy: 0.7337 - val_loss: 0.5089 - val_accuracy: 0.8200\nEpoch 112/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5998 - accuracy: 0.7300 - val_loss: 0.5096 - val_accuracy: 0.8200\nEpoch 113/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5859 - accuracy: 0.7325 - val_loss: 0.5097 - val_accuracy: 0.8200\nEpoch 114/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5886 - accuracy: 0.7275 - val_loss: 0.5101 - val_accuracy: 0.8200\nEpoch 115/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5987 - accuracy: 0.7287 - val_loss: 0.5102 - val_accuracy: 0.8200\nEpoch 116/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5842 - accuracy: 0.7312 - val_loss: 0.5098 - val_accuracy: 0.8200\nEpoch 117/200\n","name":"stdout"},{"output_type":"stream","text":"8/8 [==============================] - 31s 4s/step - loss: 0.5947 - accuracy: 0.7287 - val_loss: 0.5095 - val_accuracy: 0.8200\nEpoch 118/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5901 - accuracy: 0.7337 - val_loss: 0.5088 - val_accuracy: 0.8200\nEpoch 119/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5935 - accuracy: 0.7287 - val_loss: 0.5086 - val_accuracy: 0.8200\nEpoch 120/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5847 - accuracy: 0.7375 - val_loss: 0.5080 - val_accuracy: 0.8200\nEpoch 121/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5975 - accuracy: 0.7275 - val_loss: 0.5083 - val_accuracy: 0.8200\nEpoch 122/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5829 - accuracy: 0.7350 - val_loss: 0.5066 - val_accuracy: 0.8200\nEpoch 123/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5931 - accuracy: 0.7287 - val_loss: 0.5066 - val_accuracy: 0.8200\nEpoch 124/200\n8/8 [==============================] - 40s 5s/step - loss: 0.5898 - accuracy: 0.7287 - val_loss: 0.5072 - val_accuracy: 0.8200\nEpoch 125/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5862 - accuracy: 0.7375 - val_loss: 0.5070 - val_accuracy: 0.8200\nEpoch 126/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5952 - accuracy: 0.7237 - val_loss: 0.5071 - val_accuracy: 0.8200\nEpoch 127/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5876 - accuracy: 0.7312 - val_loss: 0.5072 - val_accuracy: 0.8200\nEpoch 128/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5864 - accuracy: 0.7312 - val_loss: 0.5069 - val_accuracy: 0.8200\nEpoch 129/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5953 - accuracy: 0.7325 - val_loss: 0.5075 - val_accuracy: 0.8200\nEpoch 130/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5852 - accuracy: 0.7312 - val_loss: 0.5079 - val_accuracy: 0.8200\nEpoch 131/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5957 - accuracy: 0.7300 - val_loss: 0.5075 - val_accuracy: 0.8200\nEpoch 132/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5957 - accuracy: 0.7312 - val_loss: 0.5070 - val_accuracy: 0.8200\nEpoch 133/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5938 - accuracy: 0.7325 - val_loss: 0.5071 - val_accuracy: 0.8200\nEpoch 134/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5846 - accuracy: 0.7325 - val_loss: 0.5072 - val_accuracy: 0.8200\nEpoch 135/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5868 - accuracy: 0.7350 - val_loss: 0.5073 - val_accuracy: 0.8200\nEpoch 136/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5817 - accuracy: 0.7337 - val_loss: 0.5075 - val_accuracy: 0.8200\nEpoch 137/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5914 - accuracy: 0.7312 - val_loss: 0.5070 - val_accuracy: 0.8200\nEpoch 138/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5964 - accuracy: 0.7287 - val_loss: 0.5069 - val_accuracy: 0.8200\nEpoch 139/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5873 - accuracy: 0.7300 - val_loss: 0.5061 - val_accuracy: 0.8200\nEpoch 140/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5940 - accuracy: 0.7300 - val_loss: 0.5049 - val_accuracy: 0.8200\nEpoch 141/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5812 - accuracy: 0.7337 - val_loss: 0.5037 - val_accuracy: 0.8200\nEpoch 142/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5832 - accuracy: 0.7375 - val_loss: 0.5034 - val_accuracy: 0.8200\nEpoch 143/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5810 - accuracy: 0.7300 - val_loss: 0.5025 - val_accuracy: 0.8200\nEpoch 144/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5846 - accuracy: 0.7337 - val_loss: 0.5029 - val_accuracy: 0.8200\nEpoch 145/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5868 - accuracy: 0.7350 - val_loss: 0.5030 - val_accuracy: 0.8200\nEpoch 146/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5966 - accuracy: 0.7312 - val_loss: 0.5031 - val_accuracy: 0.8200\nEpoch 147/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5844 - accuracy: 0.7325 - val_loss: 0.5027 - val_accuracy: 0.8200\nEpoch 148/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5757 - accuracy: 0.7350 - val_loss: 0.5023 - val_accuracy: 0.8200\nEpoch 149/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5822 - accuracy: 0.7300 - val_loss: 0.5024 - val_accuracy: 0.8200\nEpoch 150/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5836 - accuracy: 0.7325 - val_loss: 0.5016 - val_accuracy: 0.8200\nEpoch 151/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5817 - accuracy: 0.7362 - val_loss: 0.5013 - val_accuracy: 0.8200\nEpoch 152/200\n8/8 [==============================] - 39s 5s/step - loss: 0.5910 - accuracy: 0.7325 - val_loss: 0.5015 - val_accuracy: 0.8200\nEpoch 153/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5838 - accuracy: 0.7350 - val_loss: 0.5015 - val_accuracy: 0.8200\nEpoch 154/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5927 - accuracy: 0.7350 - val_loss: 0.5018 - val_accuracy: 0.8200\nEpoch 155/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5864 - accuracy: 0.7325 - val_loss: 0.5018 - val_accuracy: 0.8200\nEpoch 156/200\n8/8 [==============================] - 32s 4s/step - loss: 0.5935 - accuracy: 0.7362 - val_loss: 0.5020 - val_accuracy: 0.8200\nEpoch 157/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5883 - accuracy: 0.7337 - val_loss: 0.5020 - val_accuracy: 0.8200\nEpoch 158/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5802 - accuracy: 0.7312 - val_loss: 0.5009 - val_accuracy: 0.8200\nEpoch 159/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5826 - accuracy: 0.7325 - val_loss: 0.4998 - val_accuracy: 0.8200\nEpoch 160/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5809 - accuracy: 0.7325 - val_loss: 0.4989 - val_accuracy: 0.8200\nEpoch 161/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5851 - accuracy: 0.7337 - val_loss: 0.4992 - val_accuracy: 0.8200\nEpoch 162/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5909 - accuracy: 0.7312 - val_loss: 0.4998 - val_accuracy: 0.8200\nEpoch 163/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5823 - accuracy: 0.7350 - val_loss: 0.4988 - val_accuracy: 0.8200\nEpoch 164/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5848 - accuracy: 0.7362 - val_loss: 0.4981 - val_accuracy: 0.8200\nEpoch 165/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5920 - accuracy: 0.7337 - val_loss: 0.4988 - val_accuracy: 0.8200\nEpoch 166/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5871 - accuracy: 0.7350 - val_loss: 0.4995 - val_accuracy: 0.8200\nEpoch 167/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5860 - accuracy: 0.7337 - val_loss: 0.5001 - val_accuracy: 0.8200\nEpoch 168/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5906 - accuracy: 0.7312 - val_loss: 0.5005 - val_accuracy: 0.8200\nEpoch 169/200\n8/8 [==============================] - 32s 4s/step - loss: 0.5816 - accuracy: 0.7337 - val_loss: 0.4995 - val_accuracy: 0.8200\nEpoch 170/200\n8/8 [==============================] - 41s 5s/step - loss: 0.5786 - accuracy: 0.7337 - val_loss: 0.4987 - val_accuracy: 0.8200\nEpoch 171/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5746 - accuracy: 0.7325 - val_loss: 0.4981 - val_accuracy: 0.8200\nEpoch 172/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5868 - accuracy: 0.7312 - val_loss: 0.4980 - val_accuracy: 0.8200\nEpoch 173/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5832 - accuracy: 0.7312 - val_loss: 0.4984 - val_accuracy: 0.8200\nEpoch 174/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5822 - accuracy: 0.7337 - val_loss: 0.4976 - val_accuracy: 0.8200\nEpoch 175/200\n","name":"stdout"},{"output_type":"stream","text":"8/8 [==============================] - 30s 4s/step - loss: 0.5912 - accuracy: 0.7337 - val_loss: 0.4974 - val_accuracy: 0.8200\nEpoch 176/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5826 - accuracy: 0.7325 - val_loss: 0.4964 - val_accuracy: 0.8200\nEpoch 177/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5787 - accuracy: 0.7387 - val_loss: 0.4967 - val_accuracy: 0.8200\nEpoch 178/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5805 - accuracy: 0.7350 - val_loss: 0.4970 - val_accuracy: 0.8200\nEpoch 179/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5860 - accuracy: 0.7375 - val_loss: 0.4972 - val_accuracy: 0.8200\nEpoch 180/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5841 - accuracy: 0.7337 - val_loss: 0.4975 - val_accuracy: 0.8200\nEpoch 181/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5809 - accuracy: 0.7350 - val_loss: 0.4981 - val_accuracy: 0.8200\nEpoch 182/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5842 - accuracy: 0.7337 - val_loss: 0.4972 - val_accuracy: 0.8200\nEpoch 183/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5857 - accuracy: 0.7400 - val_loss: 0.4971 - val_accuracy: 0.8200\nEpoch 184/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5882 - accuracy: 0.7337 - val_loss: 0.4970 - val_accuracy: 0.8200\nEpoch 185/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5886 - accuracy: 0.7350 - val_loss: 0.4968 - val_accuracy: 0.8200\nEpoch 186/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5813 - accuracy: 0.7312 - val_loss: 0.4959 - val_accuracy: 0.8200\nEpoch 187/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5775 - accuracy: 0.7362 - val_loss: 0.4948 - val_accuracy: 0.8200\nEpoch 188/200\n8/8 [==============================] - 38s 5s/step - loss: 0.5854 - accuracy: 0.7362 - val_loss: 0.4941 - val_accuracy: 0.8200\nEpoch 189/200\n8/8 [==============================] - 29s 4s/step - loss: 0.5890 - accuracy: 0.7312 - val_loss: 0.4946 - val_accuracy: 0.8200\nEpoch 190/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5791 - accuracy: 0.7362 - val_loss: 0.4942 - val_accuracy: 0.8200\nEpoch 191/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5842 - accuracy: 0.7350 - val_loss: 0.4946 - val_accuracy: 0.8200\nEpoch 192/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5876 - accuracy: 0.7350 - val_loss: 0.4952 - val_accuracy: 0.8200\nEpoch 193/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5764 - accuracy: 0.7337 - val_loss: 0.4947 - val_accuracy: 0.8200\nEpoch 194/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5806 - accuracy: 0.7350 - val_loss: 0.4945 - val_accuracy: 0.8200\nEpoch 195/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5825 - accuracy: 0.7337 - val_loss: 0.4944 - val_accuracy: 0.8200\nEpoch 196/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5852 - accuracy: 0.7350 - val_loss: 0.4948 - val_accuracy: 0.8200\nEpoch 197/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5853 - accuracy: 0.7312 - val_loss: 0.4953 - val_accuracy: 0.8200\nEpoch 198/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5810 - accuracy: 0.7337 - val_loss: 0.4947 - val_accuracy: 0.8200\nEpoch 199/200\n8/8 [==============================] - 30s 4s/step - loss: 0.5897 - accuracy: 0.7325 - val_loss: 0.4948 - val_accuracy: 0.8200\nEpoch 200/200\n8/8 [==============================] - 31s 4s/step - loss: 0.5823 - accuracy: 0.7350 - val_loss: 0.4949 - val_accuracy: 0.8200\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f0616e0c2d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = m.evaluate(ag[800:1000,...],labeldata[800:1000])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labeldata[1200:1210]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.predict(ag[1200:1210])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.save('/kaggle/working/maskdetection.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb = tf.models.load_model(\"/kaggle/working/maskdetection.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb.predict(ag[1200:1210])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hh = [1,2,3,4,5]\nhh[:-3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}